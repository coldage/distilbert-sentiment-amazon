# experiment_manager.py
"""
å®éªŒç®¡ç†å™¨ - ç®¡ç†æ‰€æœ‰å®éªŒçš„è¿è¡Œ
"""

import os
import json
import pandas as pd
import concurrent.futures
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ExperimentManager:
    """å®éªŒç®¡ç†å™¨"""
    
    def __init__(self, output_dir="./experiment_results"):
        """åˆå§‹åŒ–å®éªŒç®¡ç†å™¨"""
        self.output_dir = output_dir
        self.experiments = []
        self.results = []
        
        # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„ç›®å½•ï¼Œä¸å†åˆ›å»ºåµŒå¥—å­ç›®å½•
        self.main_dir = output_dir
        os.makedirs(self.main_dir, exist_ok=True)
        
        logger.info(f"å®éªŒç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ä¸»è¾“å‡ºç›®å½•: {self.main_dir}")
    
    def add_experiment(self, config):
        """æ·»åŠ å®éªŒé…ç½®"""
        self.experiments.append(config)
    
    def add_experiments(self, configs):
        """æ·»åŠ å¤šä¸ªå®éªŒé…ç½®"""
        self.experiments.extend(configs)
    
    def run_all_experiments(self, data_manager, max_workers=2):
        """
        è¿è¡Œæ‰€æœ‰å®éªŒ
        
        Args:
            data_manager: DataManagerå®ä¾‹
            max_workers: æœ€å¤§å¹¶è¡Œæ•°
        """
        logger.info(f"å¼€å§‹è¿è¡Œ {len(self.experiments)} ä¸ªå®éªŒ...")
        
        self.results = []
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œè¿è¡Œ
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {}
            
            for config in self.experiments:
                # ä¸ºæ¯ä¸ªå®éªŒåˆ›å»ºè¿è¡Œå™¨
                from experiment_runner import ExperimentRunner
                runner = ExperimentRunner(config, self.main_dir)
                
                # æ ¹æ®å®éªŒçš„æ‰¹æ¬¡å¤§å°åˆ›å»ºæ•°æ®åŠ è½½å™¨
                train_dataloader, val_dataloader, test_dataloader = data_manager.create_dataloaders(
                    batch_size=config.batch_size
                )
                
                # æäº¤ä»»åŠ¡
                future = executor.submit(
                    runner.run,
                    train_dataloader,
                    val_dataloader,
                    test_dataloader
                )
                futures[future] = config.name
            
            # æ”¶é›†ç»“æœ
            for future in concurrent.futures.as_completed(futures):
                exp_name = futures[future]
                try:
                    result = future.result()
                    self.results.append(result)
                    logger.info(f"âœ… å®éªŒ {exp_name} å®Œæˆ")
                except Exception as e:
                    logger.error(f"âŒ å®éªŒ {exp_name} å¤±è´¥: {str(e)}")
        
        # ä¿å­˜ç»“æœæ±‡æ€»
        self._save_results_summary()
        
        logger.info(f"\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆ!")
        logger.info(f"æˆåŠŸ: {len(self.results)}/{len(self.experiments)}")
        
        return self.results
    
    def _save_results_summary(self):
        """ä¿å­˜æ‰€æœ‰å®éªŒç»“æœçš„æ±‡æ€»"""
        if not self.results:
            logger.warning("æ²¡æœ‰å®éªŒç»“æœå¯ä¿å­˜")
            return
        
        # æå–å…³é”®ä¿¡æ¯
        summary_data = []
        for result in self.results:
            config = result['config']
            summary_data.append({
                'experiment_name': result['experiment_name'],
                'experiment_type': config['experiment_type'],
                'learning_rate': config['learning_rate'],
                'batch_size': config['batch_size'],
                'epochs': config['epochs'],
                'best_epoch': result['best_epoch'],
                'best_val_loss': result['best_val_loss'],
                'test_accuracy': result['test_results']['accuracy'],
                'test_f1_macro': result['test_results'].get('f1_macro', 0),
                'test_roc_auc': result['test_results'].get('roc_auc', 0),
                'experiment_dir': result['experiment_dir']
            })
        
        # ä¿å­˜ä¸ºCSV
        df_summary = pd.DataFrame(summary_data)
        summary_csv_path = os.path.join(self.main_dir, "experiment_summary.csv")
        df_summary.to_csv(summary_csv_path, index=False)
        
        # ä¿å­˜ä¸ºJSON
        summary_json_path = os.path.join(self.main_dir, "experiment_summary.json")
        with open(summary_json_path, 'w') as f:
            json.dump({
                'total_experiments': len(self.experiments),
                'successful_experiments': len(self.results),
                'results': summary_data
            }, f, indent=2)
        
        logger.info(f"ğŸ“‹ å®éªŒç»“æœæ±‡æ€»å·²ä¿å­˜: {summary_csv_path}")
        
        return df_summary