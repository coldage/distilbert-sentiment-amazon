# experiment_runner.py
"""
å®éªŒè¿è¡Œå™¨ - ä¿®å¤è®­ç»ƒå‡½æ•°
"""

import os
import torch
import json
import pandas as pd
from datetime import datetime
from transformers import get_linear_schedule_with_warmup
from torch.optim import AdamW
from tqdm.auto import tqdm
import logging

# å¯¼å…¥ä½ çš„è¯„ä¼°å‡½æ•°
try:
    from evaluate import evaluate, print_evaluation_results
except ImportError:
    print("âš ï¸  Warning: evaluate.py not found, using dummy evaluate function")
    
    # ä¸´æ—¶è¯„ä¼°å‡½æ•°
    def evaluate(model, dataloader, device):
        return {'loss': 0.5, 'accuracy': 0.8, 'f1_macro': 0.8}
    
    def print_evaluation_results(results):
        print(f"Loss: {results['loss']:.4f}, Accuracy: {results['accuracy']:.4f}")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ExperimentRunner:
    """å•ä¸ªå®éªŒè¿è¡Œå™¨"""
    
    def __init__(self, config, output_dir=None):
        """
        åˆå§‹åŒ–
        
        Args:
            config: ExperimentConfigå¯¹è±¡
            output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨configä¸­çš„è·¯å¾„
        """
        self.config = config
        
        # ç¡®å®šè¾“å‡ºç›®å½•
        if output_dir:
            self.output_base = output_dir
        else:
            self.output_base = config.output_base_path
        
        # åˆ›å»ºå®éªŒç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.experiment_dir = os.path.join(self.output_base, f"{config.name}_{timestamp}")
        
        # åˆ›å»ºå­ç›®å½•
        self.checkpoint_dir = os.path.join(self.experiment_dir, "checkpoints")
        self.logs_dir = os.path.join(self.experiment_dir, "logs")
        
        os.makedirs(self.checkpoint_dir, exist_ok=True)
        os.makedirs(self.logs_dir, exist_ok=True)
        
        logger.info(f"å®éªŒè¾“å‡ºç›®å½•: {self.experiment_dir}")
    
    def run(self, train_dataloader, val_dataloader, test_dataloader):
        """
        è¿è¡Œå®éªŒ
        
        Args:
            train_dataloader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_dataloader: éªŒè¯æ•°æ®åŠ è½½å™¨
            test_dataloader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
            
        Returns:
            å®éªŒç»“æœå­—å…¸
        """
        logger.info(f"\nğŸš€ å¼€å§‹å®éªŒ: {self.config.name}")
        
        # è®¾ç½®è®¾å¤‡
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
        
        # åˆ›å»ºæ¨¡å‹
        from model_factory import ModelFactory
        model = ModelFactory.create_model(
            self.config.model_path,
            self.config.experiment_type,
            self.config.num_labels
        )
        model.to(device)
        
        # ä¼˜åŒ–å™¨
        optimizer = AdamW(
            filter(lambda p: p.requires_grad, model.parameters()),
            lr=self.config.learning_rate,
            eps=self.config.eps,
            weight_decay=self.config.weight_decay
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        total_steps = len(train_dataloader) * self.config.epochs
        scheduler = get_linear_schedule_with_warmup(
            optimizer,
            num_warmup_steps=int(total_steps * 0.1),
            num_training_steps=total_steps
        )
        
        # è®­ç»ƒå†å²
        training_stats = []
        best_val_loss = float('inf')
        best_model_state = None
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(self.config.epochs):
            logger.info(f'\nEpoch {epoch + 1}/{self.config.epochs}')
            logger.info('-' * 40)
            
            # ========== è®­ç»ƒé˜¶æ®µ ==========
            model.train()
            total_train_loss = 0
            
            progress_bar = tqdm(train_dataloader, desc="è®­ç»ƒ", leave=False)
            
            for batch in progress_bar:
                # ç§»åŠ¨åˆ°è®¾å¤‡
                batch = tuple(t.to(device) for t in batch)
                b_input_ids, b_input_mask, b_labels = batch
                
                # å‰å‘ä¼ æ’­
                model.zero_grad()
                outputs = model(
                    b_input_ids,
                    attention_mask=b_input_mask,
                    labels=b_labels
                )
                loss = outputs.loss
                total_train_loss += loss.item()
                
                # åå‘ä¼ æ’­
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), self.config.gradient_clip)
                
                # æ›´æ–°å‚æ•°
                optimizer.step()
                scheduler.step()
                optimizer.zero_grad()
                
                # æ›´æ–°è¿›åº¦æ¡
                progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})
            
            avg_train_loss = total_train_loss / len(train_dataloader)
            
            # ========== éªŒè¯é˜¶æ®µ ==========
            logger.info("è¿›è¡ŒéªŒè¯...")
            val_results = evaluate(model, val_dataloader, device)
            
            # è®°å½•ç»Ÿè®¡
            epoch_stats = {
                'epoch': epoch + 1,
                'train_loss': avg_train_loss,
                'val_loss': val_results['loss'],
                'val_accuracy': val_results['accuracy'],
                'val_f1_macro': val_results.get('f1_macro', 0),
                'val_roc_auc': val_results.get('roc_auc', 0),
                'learning_rate': scheduler.get_last_lr()[0]
            }
            training_stats.append(epoch_stats)
            
            # æ‰“å°ç»“æœ
            logger.info(f"è®­ç»ƒæŸå¤±: {avg_train_loss:.4f}")
            logger.info(f"éªŒè¯æŸå¤±: {val_results['loss']:.4f}")
            logger.info(f"éªŒè¯å‡†ç¡®ç‡: {val_results['accuracy']:.4f}")
            
            # æ£€æŸ¥æ˜¯å¦æœ€ä½³æ¨¡å‹
            if val_results['loss'] < best_val_loss:
                best_val_loss = val_results['loss']
                best_model_state = model.state_dict().copy()
                best_epoch = epoch + 1
                logger.info(f"ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹! éªŒè¯æŸå¤±: {best_val_loss:.4f}")
            
            # ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆæ¯2ä¸ªepochæˆ–æœ€åä¸€ä¸ªepochï¼‰
            if (epoch + 1) % 2 == 0 or (epoch + 1) == self.config.epochs:
                self._save_checkpoint(
                    model, optimizer, epoch + 1, val_results, training_stats
                )
        
        # ========== æœ€ç»ˆæµ‹è¯• ==========
        logger.info("\nä½¿ç”¨æœ€ä½³æ¨¡å‹è¿›è¡Œæœ€ç»ˆæµ‹è¯•...")
        
        # åŠ è½½æœ€ä½³æ¨¡å‹
        if best_model_state is not None:
            model.load_state_dict(best_model_state)
        
        # æµ‹è¯•é›†è¯„ä¼°
        test_results = evaluate(model, test_dataloader, device)
        print_evaluation_results(test_results)
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        experiment_result = self._save_experiment_results(
            model, training_stats, test_results, best_epoch, best_val_loss
        )
        
        logger.info(f"\nâœ… å®éªŒ {self.config.name} å®Œæˆ!")
        
        return experiment_result
    
    def _save_checkpoint(self, model, optimizer, epoch, val_results, training_stats):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'val_results': val_results,
            'training_stats': training_stats,
            'config': self.config.to_dict()
        }
        
        checkpoint_path = os.path.join(self.checkpoint_dir, f"epoch_{epoch:03d}.pt")
        torch.save(checkpoint, checkpoint_path)
        
        logger.info(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
        
        return checkpoint_path
    
    def _save_experiment_results(self, model, training_stats, test_results, best_epoch, best_val_loss):
        """ä¿å­˜å®éªŒæœ€ç»ˆç»“æœ"""
        # ä¿å­˜æ¨¡å‹
        model_path = os.path.join(self.experiment_dir, "final_model.pth")
        torch.save(model.state_dict(), model_path)
        
        # ä¿å­˜è®­ç»ƒå†å²
        history_path = os.path.join(self.logs_dir, "training_history.json")
        with open(history_path, 'w') as f:
            json.dump(training_stats, f, indent=2)
        
        # ä¿å­˜CSV
        df_stats = pd.DataFrame(training_stats)
        csv_path = os.path.join(self.logs_dir, "training_history.csv")
        df_stats.to_csv(csv_path, index=False)
        
        # å®éªŒæ€»ç»“
        experiment_result = {
            'experiment_name': self.config.name,
            'config': self.config.to_dict(),
            'training_stats': training_stats,
            'test_results': test_results,
            'best_epoch': best_epoch,
            'best_val_loss': best_val_loss,
            'test_accuracy': test_results['accuracy'],
            'test_f1': test_results.get('f1_macro', 0),
            'experiment_dir': self.experiment_dir,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        summary_path = os.path.join(self.experiment_dir, "experiment_summary.json")
        with open(summary_path, 'w') as f:
            json.dump(experiment_result, f, indent=2)
        
        logger.info(f"ğŸ“Š å®éªŒç»“æœå·²ä¿å­˜åˆ°: {self.experiment_dir}")
        
        return experiment_result